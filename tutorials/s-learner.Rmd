---
title: "S-Learner Tutorial"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  results = "markup",
  warning = FALSE,
  message = FALSE
)
```

```{r}
library(multibias)
library(tidyverse)
library(tidymodels)
library(themis)
library(boot)
```

```{r}
summary(df_uc_source)

df <- df_uc_source %>%
  mutate(
    Y_bi = as.factor(Y_bi),
    X_bi = as.factor(X_bi)
  )

print(nrow(df))
head(df)

table(df$Y_bi)
```

```{r}
# split data
set.seed(123)
data_split <- initial_split(df, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

table(train_data$Y_bi)
table(test_data$Y_bi)
```

# 1. Fit outcome model on train data

```{r}
# create recipe
model_recipe <- recipe(Y_bi ~ X_bi + C1 + C2 + C3 + U, data = train_data)

# specify model
lr_mod <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# create workflow
lr_wf <- workflow() %>%
  add_recipe(model_recipe) %>%
  add_model(lr_mod)
```

```{r}
# fit final model on training data
final_fit <- fit(lr_wf, train_data)

# View model summary
final_fit %>%
  extract_fit_engine() %>%
  summary()
```

# 2. Compare train vs test performance

```{r}
# train performance
train_pred <- predict(final_fit, train_data, type = "prob")
train_pred_class <- predict(final_fit, train_data, type = "class")

train_results <- train_data %>%
  select(Y_bi) %>%
  bind_cols(train_pred) %>%
  bind_cols(train_pred_class)

# confusion matrix
conf_mat(train_results, truth = Y_bi, estimate = .pred_class)

# Accuracy and ROC AUC
accuracy(train_results, truth = Y_bi, estimate = .pred_class)
roc_auc(train_results, truth = Y_bi, .pred_1, event_level = "second")
```

Train ROC_AUC = 0.683

```{r}
# test performance
test_pred <- predict(final_fit, test_data, type = "prob")
test_pred_class <- predict(final_fit, test_data, type = "class")

test_results <- test_data %>%
  select(Y_bi) %>%
  bind_cols(test_pred) %>%
  bind_cols(test_pred_class)

# confusion matrix
conf_mat(test_results, truth = Y_bi, estimate = .pred_class)

# Accuracy and ROC AUC
accuracy(test_results, truth = Y_bi, estimate = .pred_class)
roc_auc(test_results, truth = Y_bi, .pred_1, event_level = "second")
```

Test ROC_AUC = 0.683

# 3. Obtain CATE in train data

```{r}
df_x1 <- train_data %>%
  mutate(X_bi = factor(1, levels = levels(df$X_bi)))
df_x0 <- train_data %>%
  mutate(X_bi = factor(0, levels = levels(df$X_bi)))

pred_prob_x1 <- predict(final_fit, df_x1, type = "prob")$.pred_1
pred_prob_x0 <- predict(final_fit, df_x0, type = "prob")$.pred_1

cate <- pred_prob_x1 - pred_prob_x0

print(mean(cate))
print(sd(cate))
print(quantile(cate, c(0.025, 0.975))) # not confidence interval
```

Train CATE = 0.102

On average, across all individuals (with their covariate values), treatment (X=1) increases the probability of the outcome (Y=1) by 10.2 percentage points compared to control (X=0).

```{r}
# cate_summary <- tibble(
#   mean_cate = mean(cate),
#   sd_cate = sd(cate),
#   q025 = quantile(cate, 0.025),
#   q975 = quantile(cate, 0.975)
# )

ggplot(tibble(cate = cate), aes(x = cate)) +
  geom_histogram(aes(y = after_stat(density)),
    binwidth = 0.01,
    fill = "steelblue",
    alpha = 0.7,
    color = "white"
  ) +
  geom_density(color = "darkblue", linewidth = 1) +
  labs(
    title = "Distribution of Conditional Average Treatment Effects (CATE)",
    x = "CATE (P(Y=1|X=1,C) - P(Y=1|X=0,C))",
    y = "Density"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    legend.position = "bottom"
  )
```

# 4. Compare to CATE in test data

```{r}
df_x1 <- test_data %>%
  mutate(X_bi = factor(1, levels = levels(df$X_bi)))
df_x0 <- test_data %>%
  mutate(X_bi = factor(0, levels = levels(df$X_bi)))

pred_prob_x1 <- predict(final_fit, df_x1, type = "prob")$.pred_1
pred_prob_x0 <- predict(final_fit, df_x0, type = "prob")$.pred_1

cate_test <- pred_prob_x1 - pred_prob_x0

print(mean(cate_test))
print(sd(cate_test))
print(quantile(cate_test, c(0.025, 0.975))) # not confidence interval
```

Test CATE = 0.102

# 5. Bootstrap confidence intervals for mean CATE

To obtain valid confidence intervals for the mean CATE, we need to account for uncertainty in the model parameters. Let's use bootstrap resampling:

```{r}
# Function to compute mean CATE on a bootstrap sample
cate_boot_fxn <- function(data, indices) {
  # Get bootstrap sample
  boot_data <- data[indices, ]

  # Create recipe and workflow (same as before)
  boot_recipe <- recipe(Y_bi ~ X_bi + C1 + C2 + C3 + U, data = boot_data)

  boot_wf <- workflow() %>%
    add_recipe(boot_recipe) %>%
    add_model(lr_mod)

  # Fit model on bootstrap sample
  boot_fit <- fit(boot_wf, boot_data)

  # Compute CATE for each individual in bootstrap sample
  boot_x1 <- boot_data %>%
    mutate(X_bi = factor(1, levels = levels(boot_data$X_bi)))
  boot_x0 <- boot_data %>%
    mutate(X_bi = factor(0, levels = levels(boot_data$X_bi)))

  pred_x1 <- predict(boot_fit, boot_x1, type = "prob")$.pred_1
  pred_x0 <- predict(boot_fit, boot_x0, type = "prob")$.pred_1

  cate_boot <- pred_x1 - pred_x0

  # Return mean CATE
  return(mean(cate_boot))
}
```

```{r}
# Run bootstrap on training data
set.seed(123)
n_reps <- 200

boot_results_train <- boot::boot(
  data = train_data,
  statistic = cate_boot_fxn,
  R = n_reps
)

boot_ci_train <- boot::boot.ci(boot_results_train, type = "perc")

print(paste("Mean CATE (train):", round(median(boot_results_train$t), 4)))
print(paste(
  "95% CI for Mean CATE (train):",
  round(boot_ci_train$percent[4], 4), "to",
  round(boot_ci_train$percent[5], 4)
))
```

CATE = 0.1017 (95% CI:  0.0958 to 0.1080)

```{r}
# Run bootstrap on test data
set.seed(123)
boot_results_test <- boot::boot(
  data = test_data,
  statistic = cate_boot_fxn,
  R = n_reps
)

boot_ci_test <- boot.ci(boot_results_test, type = "perc")

print(paste("Mean CATE (test):", round(median(boot_results_test$t), 4)))
print(paste(
  "95% CI for Mean CATE (test):",
  round(boot_ci_test$percent[4], 4), "to",
  round(boot_ci_test$percent[5], 4)
))
```

CATE = 0.1024 (95% CI: 0.0913 to 0.1157)

# 6. Assess heterogeneity

```{r}
test_data$cate <- cate_test

test_data %>%
  mutate(cate_group = if_else(cate > median(cate), "High", "Low")) %>%
  group_by(cate_group) %>%
  summarize(
    cate_mean = mean(cate),
    Y_mean = mean(as.numeric(Y_bi) - 1),
    X_mean = mean(as.numeric(X_bi) - 1),
    C1_mean = mean(C1),
    C2_mean = mean(C2),
    C3_mean = mean(C3),
    U_mean = mean(U)
  )
```

  cate_group cate_mean Y_mean X_mean C1_mean C2_mean C3_mean U_mean
  <chr>          <dbl>  <dbl>  <dbl>   <dbl>   <dbl>   <dbl>  <dbl>
1 High          0.134   0.257  0.410   0.501   0       0.803  1
2 Low           0.0800  0.123  0.275   0.494   0.335   0.802  0.167